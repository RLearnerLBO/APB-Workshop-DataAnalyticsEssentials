getwd()
#
df <- USArrests
#K Means
#https://uc-r.github.io/kmeans_clustering
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
df <- USArrests
df <- na.omit(df)
df <- scale(df)
distance <- get_dist(df)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
k2 <- kmeans(df, centers = 2, nstart = 25)
fviz_cluster(k2, data = df)
df %>%
as_tibble() %>%
mutate(cluster = k2$cluster,
state = row.names(USArrests)) %>%
ggplot(aes(UrbanPop, Murder, color = factor(cluster), label = state)) +
geom_text()
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
set.seed(123)
fviz_nbclust(df, kmeans, method = "wss")
# Compute k-means clustering with k = 4
set.seed(123)
final <- kmeans(df, 4, nstart = 25)
print(final)
fviz_cluster(final, data = df)
fviz_cluster(final, data = df)
#Auto-encoder
# autoencoder in keras
library(keras)
# set training data
###
model3 <- keras_model_sequential()
Y
install_tensorflow()
library(keras)
install_tensorflow()
install_tensorflow() conda activate r-reticulate
conda activate r-reticulate
install.packages("reticulate")
install_tensorflow()
library(keras)
install_tensorflow()
install.packages("tensorflow")
install.packages("tensorflow")
library(tensorflow)
install_tensorflow()
library(tensorflow)
install_tensorflow()
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(tensorflow)
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(keras)
install_keras()
install_keras(tensorflow = "2.1")
install_keras()
library(keras)
install_keras()
#
library(tidyverse)  # data manipulation
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
df <- USArrests
df <- na.omit(df)
df <- scale(df)
library(keras)
#
# T-SNE
library(Rtsne)
library(ggplot2)
data(iris)
iris.unique <- as.matrix(iris[,1:4])
iris.unique <- iris.unique[!duplicated(iris.unique),]
iris.rtsne <- Rtsne(iris.unique, dims = 2, initial_dims = 50, perplexity = 30)
install.packages(c("colorspace", "curl", "googledrive", "isoband", "Rcpp", "spatstat.geom", "xfun"))
install.packages(c("Matrix", "mgcv"), lib="C:/Program Files/R/R-4.1.0/library")
install.packages(c("colorspace", "curl", "googledrive", "isoband", "Rcpp", "spatstat.geom", "xfun"))
install.packages(c("colorspace", "curl", "googledrive", "isoband", "Rcpp", "spatstat.geom", "xfun"))
install.packages(c("colorspace", "curl", "googledrive", "isoband", "Rcpp", "spatstat.geom", "xfun"))
#
# T-SNE
library(Rtsne)
library(ggplot2)
data(iris)
iris.unique <- as.matrix(iris[,1:4])
iris.unique <- iris.unique[!duplicated(iris.unique),]
iris.rtsne <- Rtsne(iris.unique, dims = 2, initial_dims = 50, perplexity = 30)
plotdata <- data.frame(iris.umap$layout)
View(iris.rtsne)
iris.rtsne$Y
plotdata <- as.data.frame(iris.rtsne$Y)
View(plotdata)
plotdata <- as.data.frame(iris.rtsne$Y)
ggplot(plotdata, aes(x=V1,y=V2)) + geom_point(aes(color=iris$Species))
data(iris)
iris.unique <- iris.unique[!duplicated(iris.unique),]
label <- iris.unique$Species
View(iris.unique)
data(iris)
iris
iris.unique <- iris.unique[!duplicated(iris.unique),]
label <- iris.unique$Species
label <- iris.uniquep[,5]
label <- iris.unique[,5]
iris.unique <- iris[!duplicated(iris),]
label <- iris.unique[,5]
iris.unique <- as.matrix(iris[,1:4])
iris.unique <- iris[!duplicated(iris),]
label <- iris.unique[,5]
iris.unique <- as.matrix(iris.unique[,1:4])
iris.rtsne <- Rtsne(iris.unique, dims = 2, initial_dims = 50, perplexity = 30)
plotdata <- as.data.frame(iris.rtsne$Y)
ggplot(plotdata, aes(x=V1,y=V2)) + geom_point(aes(color=label))
#https://fderyckel.github.io/machinelearningwithr/knnchapter.html
df <- data(iris) ##load data
head(iris) ## see the studcture
##Generate a random number that is 90% of the total number of rows in dataset.
ran <- sample(1:nrow(iris), 0.9 * nrow(iris))
##the normalization function is created
nor <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
##Run nomalization on first 4 coulumns of dataset because they are the predictors
iris_norm <- as.data.frame(lapply(iris[, c(1, 2, 3, 4)], nor))
summary(iris_norm)
plor(iris_norm)
plot(iris_norm)
iris_train <- iris_norm[ran, ]
##extract testing set
iris_test <- iris_norm[-ran, ]
##extract 5th column of train dataset because it will be used as 'cl' argument in knn function.
iris_target_category <- iris[ran, 5]
##extract 5th column if test dataset to measure the accuracy
iris_test_category <- iris[-ran, 5]
##load the package class
library(class)
##run knn function
pr <- knn(iris_train, iris_test, cl = iris_target_category, k = 13)
##create confusion matrix
tab <- table(pr, iris_test_category)
accuracy <- function(x) {
sum(diag(x) / (sum(rowSums(x)))) * 100
}
accuracy(tab)
tab
##create confusion matrix
tab <- table(model_knn, iris_test_category)
##run knn function
model_knn <- knn(iris_train, iris_test, cl = iris_target_category, k = 13)
##create confusion matrix
tab <- table(model_knn, iris_test_category)
tab
install.packages("ISLR")
library(ISLR)
# Load the party package. It will automatically load other
# dependent packages.
library(party)
# Create the input data frame.
input.dat <- readingSkills[c(1:105),]
# Give the chart file a name.
png(file = "decision_tree.png")
# Save the file.
dev.off()
# Create the tree.
output.tree <- ctree(
nativeSpeaker ~ age + shoeSize + score,
data = input.dat)
# Plot the tree.
plot(output.tree)
View(input.dat)
